{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9c10289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70d752",
   "metadata": {},
   "source": [
    "# Loading The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16210a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nlp_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab14d05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion\n",
       "0  i seriously hate one subject to death but now ...    fear\n",
       "1                 im so full of life i feel appalled   anger\n",
       "2  i sit here to write i start to dig out my feel...    fear\n",
       "3  ive been really angry with r and i feel like a...     joy\n",
       "4  i feel suspicious if there is no one outside l...    fear"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e7fe0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>i begun to feel distressed for you</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>i left feeling annoyed and angry thinking that...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>i were to ever get married i d have everything...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>i feel reluctant in applying there because i w...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>i just wanted to apologize to you because i fe...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment Emotion\n",
       "5932                 i begun to feel distressed for you    fear\n",
       "5933  i left feeling annoyed and angry thinking that...   anger\n",
       "5934  i were to ever get married i d have everything...     joy\n",
       "5935  i feel reluctant in applying there because i w...    fear\n",
       "5936  i just wanted to apologize to you because i fe...   anger"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6228283",
   "metadata": {},
   "source": [
    "# preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1571b1f",
   "metadata": {},
   "source": [
    "## 1) Analyzing Non-String Elements in a DataFrame\n",
    "\n",
    "The code snippet leverages pandas to identify non-string elements within a DataFrame. It begins by applying the applymap() method to the DataFrame df, using a lambda function that checks if each element is not a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "262bb912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.value_counts of       Comment  Emotion\n",
       "0       False    False\n",
       "1       False    False\n",
       "2       False    False\n",
       "3       False    False\n",
       "4       False    False\n",
       "...       ...      ...\n",
       "5932    False    False\n",
       "5933    False    False\n",
       "5934    False    False\n",
       "5935    False    False\n",
       "5936    False    False\n",
       "\n",
       "[5937 rows x 2 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_string_mask = df.applymap(lambda x: not isinstance(x, str))\n",
    "non_string_mask.value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dc6fa6",
   "metadata": {},
   "source": [
    "## 2) Converting Text to Lowercase in DataFrame Columns\n",
    "\n",
    "The code snippet demonstrates how to convert the text in specific columns of a pandas DataFrame to lowercase. The first line, df['Comment'].str.lower(), targets the Comment column, applying the str.lower() method to each string element within that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f62a1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        fear\n",
       "1       anger\n",
       "2        fear\n",
       "3         joy\n",
       "4        fear\n",
       "        ...  \n",
       "5932     fear\n",
       "5933    anger\n",
       "5934      joy\n",
       "5935     fear\n",
       "5936    anger\n",
       "Name: Emotion, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Comment'].str.lower()\n",
    "df['Emotion'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aba4e8",
   "metadata": {},
   "source": [
    "## 3) Removing Punctuation from Text\n",
    "\n",
    "The code defines a function, remove_punctuation, designed to eliminate punctuation from a given text string. Within the function, the variable punctuation is assigned the value of string.punctuation, which contains all standard punctuation characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e303d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1127901",
   "metadata": {},
   "source": [
    "This is the set of punctuations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65bbed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuation = string.punctuation\n",
    "    return text.translate(str.maketrans('','',punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0e36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Comment','Emotion']] = df[['Comment','Emotion']].applymap(lambda x:remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0210316e",
   "metadata": {},
   "source": [
    "## 4) Removing Stop Words from Text\n",
    "\n",
    "The code snippet defines a function, remove_stopwors, that is designed to remove stop words from a given text string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1700d88",
   "metadata": {},
   "source": [
    "### Listing English Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6c66b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8327815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = stopwords.words('english')\n",
    "def remove_stopwors(text):\n",
    "    return \" \".join([word for word in text.split() if word not in stop_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad50e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Comment','Emotion']] = df[['Comment','Emotion']].applymap(lambda x:remove_stopwors(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcefa031",
   "metadata": {},
   "source": [
    "## 5) Stemming Words in a Text\n",
    "\n",
    "The code snippet defines a function, stem_words, which is designed to perform stemming on each word in a given text string using the Porter stemming algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c4bb5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c3765ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Comment'] = df['Comment'].apply(lambda x: stem_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1ac1e",
   "metadata": {},
   "source": [
    "## 6) Tokenizing Text\n",
    "\n",
    "The code snippet defines a function, tocken, which is designed to tokenize a given text string into individual words or tokens using the word_tokenize function from the Natural Language Toolkit (nltk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "219e30bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tocken(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d50fd70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Comment','Emotion']] = df[['Comment','Emotion']].applymap(tocken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c02b4f",
   "metadata": {},
   "source": [
    "## 7) Splitting Data into Training and Testing Sets\n",
    "\n",
    "The code snippet demonstrates how to split a DataFrame into training and testing sets for machine learning tasks using the train_test_split function from the sklearn.model_selection module. Here's a detailed breakdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b55eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_raw,x_test_raw,y_train_raw,y_test_raw = train_test_split(df['Comment'],df['Emotion'],test_size=0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3165c13",
   "metadata": {},
   "source": [
    "# * Transforming Text Data Using TF-IDF Vectorization\n",
    "\n",
    "TF-IDF vectorization is crucial for natural language processing tasks because it transforms textual data into numerical format, making it suitable for input into machine learning algorithms. It helps to weigh the importance of words, giving more significance to those that are unique to specific documents while reducing the weight of commonly used words across the corpus. This representation enhances the model's ability to differentiate between texts based on their content.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03da8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer()\n",
    "x_train = tfid.fit_transform(x_train_raw)\n",
    "x_test = tfid.transform(x_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c4947",
   "metadata": {},
   "source": [
    "# * Encoding Target Labels Using Label Encoding\n",
    "\n",
    "Label encoding is an essential preprocessing step when working with categorical target variables in machine learning. By converting categories into numerical values, it enables the use of algorithms that require numerical input. This approach is particularly useful for classification tasks where the target variable consists of distinct categories (e.g., emotions, classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c54ebf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train_raw)\n",
    "y_test = lb.transform(y_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404fec31",
   "metadata": {},
   "source": [
    "# * Training a Multinomial Naive Bayes Model\n",
    "\n",
    "Multinomial Naive Bayes is a simple yet effective algorithm for text classification tasks, such as sentiment analysis or emotion detection. It assumes that the features are conditionally independent given the class label and calculates the probabilities of each class based on the frequencies of the features in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06d4a745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac989ba7",
   "metadata": {},
   "source": [
    "# * Training a Support Vector Machine Model\n",
    "\n",
    "SVM is a robust classification technique that can handle both linear and nonlinear classification problems. It is particularly effective in high-dimensional spaces and is well-suited for text classification tasks, such as sentiment analysis and emotion detection, especially when combined with vectorization techniques like TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "671d2b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC()\n",
    "svm_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d58eec2",
   "metadata": {},
   "source": [
    "## Making Predictions with the Naive Bayes Model\n",
    "\n",
    "Making predictions with a trained model is a crucial step in the machine learning workflow. The predictions can then be compared with the true labels (y_test) to evaluate the model's performance. Common evaluation metrics include accuracy, precision, recall, and F1-score, which help assess how well the model performs in classifying the target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ba20f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nb = nb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9e7767",
   "metadata": {},
   "source": [
    "## Making Predictions with the Support Vector Machine Model\n",
    "\n",
    "Making predictions with the SVM model is an important part of the machine learning process. The predictions can be compared against the true labels (y_test) to evaluate the model's performance. Common evaluation metrics to consider include accuracy, precision, recall, and F1-score, which provide insights into the effectiveness of the model in classifying the target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65eb0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm = svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d20b20",
   "metadata": {},
   "source": [
    "## Generating Classification Reports for Model Evaluation\n",
    "\n",
    "The classification report provides a detailed breakdown of the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e728ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_nb = classification_report(y_test, pred_nb)\n",
    "report_svm = classification_report(y_test, pred_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f1a81",
   "metadata": {},
   "source": [
    "## Calculating Accuracy for the Naive Bayes Model\n",
    "\n",
    "Accuracy is a straightforward metric that gives an overall indication of the model's performance. However, it may not always be the best metric to rely on, especially in cases where the class distribution is imbalanced. It’s often useful to complement accuracy with other evaluation metrics like precision, recall, and F1-score for a more comprehensive understanding of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a83bd807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.898989898989899"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_nb = accuracy_score(y_test,pred_nb)\n",
    "accuracy_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a59531",
   "metadata": {},
   "source": [
    "## Calculating Accuracy for the Support Vector Machine Model\n",
    "\n",
    "Accuracy gives a straightforward indication of the model's performance. However, like with the Naive Bayes model, it's important to consider other metrics (like precision, recall, and F1-score) to obtain a more complete view of the model's effectiveness, especially in cases of class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8dbbee68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9141414141414141"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accurancy_svm = accuracy_score(y_test,pred_svm)\n",
    "accurancy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "771d5531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.87      0.94      0.90       392\\n           1       0.92      0.88      0.90       416\\n           2       0.91      0.88      0.89       380\\n\\n    accuracy                           0.90      1188\\n   macro avg       0.90      0.90      0.90      1188\\nweighted avg       0.90      0.90      0.90      1188\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ff9b14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.90      0.92      0.91       392\\n           1       0.96      0.87      0.91       416\\n           2       0.89      0.95      0.92       380\\n\\n    accuracy                           0.91      1188\\n   macro avg       0.92      0.92      0.91      1188\\nweighted avg       0.92      0.91      0.91      1188\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9603cfa6",
   "metadata": {},
   "source": [
    "#  Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ff7faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [nb_model,svm_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa5370bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best model\n",
      "Model: SVC() with f1_score: 0.9140861076081777\n"
     ]
    }
   ],
   "source": [
    "def best(models):\n",
    "    best_model = None\n",
    "    best_f1 = 0\n",
    "\n",
    "    for model in models:\n",
    "        model.fit(x_train, y_train)\n",
    "        pre1 = model.predict(x_test)\n",
    "        f1 = f1_score(y_test,pre1,average=\"weighted\")\n",
    "    \n",
    "        if f1>best_f1:\n",
    "            best_f1 = f1\n",
    "            best_model = model\n",
    "        \n",
    "    print(\"\\nbest model\")\n",
    "    print(f\"Model: {best_model} with f1_score: {best_f1}\")\n",
    "    \n",
    "best(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09117a0",
   "metadata": {},
   "source": [
    "## SVM Model Evaluation Report: Justification for Selection\n",
    "The classification report for the Support Vector Machine (SVM) model provides compelling evidence that it is an optimal choice for emotion classification tasks. Here’s a breakdown of the key metrics that support the conclusion that the SVM model outperforms alternatives:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e6632",
   "metadata": {},
   "source": [
    "## High Precision:\n",
    "\n",
    "The SVM model achieves precision scores of 0.90 for class 0, 0.96 for class 1, and 0.89 for class 2. These scores indicate that the model is highly effective at correctly identifying positive instances for each class, suggesting low rates of false positives. This is particularly crucial in emotion classification, where accurate identification of emotions is essential.\n",
    "## Strong Recall:\n",
    "\n",
    "The recall values of 0.92 for class 0, 0.87 for class 1, and 0.95 for class 2 demonstrate the model’s capability to capture a significant proportion of actual positive instances. Although class 1 shows a slightly lower recall, the overall performance remains strong, indicating that the model is proficient at identifying the majority of true emotional expressions.\n",
    "## Balanced F1-Scores:\n",
    "\n",
    "The F1-scores for the three classes are all above 0.91, reflecting a commendable balance between precision and recall. This balance is essential in emotion classification, where both the accuracy of identifying emotions and the minimization of misclassifications are critical for reliable results.\n",
    "## Overall Accuracy:\n",
    "\n",
    "With an overall accuracy of 0.91, the SVM model correctly classifies 91% of the instances in the test set. This high accuracy underscores the model’s effectiveness and reliability in handling the complexities of emotion classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46058570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
